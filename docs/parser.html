<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>nafparserpy.parser API documentation</title>
<meta name="description" content="Wraps lxml to facilitate handling of NAF documents" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>nafparserpy.parser</code></h1>
</header>
<section id="section-intro">
<p>Wraps lxml to facilitate handling of NAF documents</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Wraps lxml to facilitate handling of NAF documents
&#34;&#34;&#34;
import datetime
import re
from typing import Any, Tuple, Dict, List

from nafparserpy.layers.naf_header import NafHeader, LP, LinguisticProcessors
from nafparserpy.layers.raw import Raw
from lxml import etree

from nafparserpy.layers.factory import create_from_node, create_from_elements

NAF_VERSION = &#39;3.3&#39;


def split_naf_header_attrs(attrs):
    &#34;&#34;&#34;Split input attributes in public or fileDesc attributes

    Parameters
    ----------
    attrs : dict
        dictionary of public/fileDesc attributes

    Returns
    -------
    a tuple of attribute dictionaries for fileDesc and public

    Raises
    ------
    KeyError: if the input dictionary contains keywords not pertaining to public/fileDesc attributes
        &#34;&#34;&#34;
    public_attrs = {}
    filedesc_attrs = {}
    public_keys = [&#39;publicId&#39;, &#39;uri&#39;]
    filedesc_keys = [&#39;title&#39;, &#39;author&#39;, &#39;creationtime&#39;, &#39;filename&#39;, &#39;filetype&#39;, &#39;pages&#39;]
    for k in attrs:
        if k in public_keys:
            public_attrs.update({k: attrs[k]})
        elif k in filedesc_keys:
            filedesc_attrs.update({k: attrs[k]})
        else:
            raise KeyError(&#39;unknown public/fileDesc key: {}&#39;.format(k))
    return filedesc_attrs, public_attrs


def validate_dtd(tree, dtd=&#39;naf_v3.3.dtd&#39;):
    &#34;&#34;&#34;Validate tree against DTD

    Parameters
    ----------
    tree : ElementTree
        NAF tree
    dtd : str
        path to DTD

    Raises
    ------
    ValueError : if tree is not valid
    &#34;&#34;&#34;
    with open(dtd) as infile:
        dtd = etree.DTD(infile)
    if not dtd.validate(tree.getroot()):
        raise ValueError(f&#34;Input tree does not conform to DTD {dtd}&#34;)


def remove_lps(ling_processors_layer_node):
    lps = [child for child in ling_processors_layer_node]
    for lp in lps:
        ling_processors_layer_node.remove(lp)


class NafParser:
    def __init__(self, tree=None, lang=&#39;en&#39;, version=None, decorate=True, **attrs):
        &#34;&#34;&#34;
        Create a NAF document from an existing tree or from scratch.

        Parameters
        ----------
        tree : etree
            input tree
        lang : str
            document language, defaults to `en`. This parameter is ignored if tree is not None
        version : str
            NAF version, defaults to `parser.NAF_VERSION`; ignored if tree is not None
        decorate : bool
            adds covered text to span nodes
        attrs : dict
            nafHeader fileDesc and public attributes; ignored if tree is not None
        &#34;&#34;&#34;
        self.decorate = decorate
        naf_version = NAF_VERSION
        if version is not None:
            naf_version = version
        if tree is None:
            self.tree = etree.ElementTree(etree.Element(&#39;NAF&#39;))
            self.root = self.tree.getroot()
            self.root.set(&#39;{http://www.w3.org/XML/1998/namespace}lang&#39;, lang)
            self.root.set(&#39;version&#39;, naf_version)
            if attrs:
                filedesc_attrs, public_attrs = split_naf_header_attrs(attrs)
                self.add_naf_header(fileDesc_attrs=filedesc_attrs, public_attrs=public_attrs)
            self.id_map = {}
        else:
            self.tree = tree
            self.root = self.tree.getroot()
            self.id_map = self.targets2indices()

    @staticmethod
    def load(naf_file, validate_against_dtd=False, decorate=True):
        &#34;&#34;&#34;Create a NAF document from a NAF file

        Parameters
        ----------
        naf_file : str
            path to NAF file
        validate_against_dtd : bool
            validates input tree against DTD if True
        decorate : bool
            adds covered text to span nodes

        Raises
        ------
        ValueError: if `validate_against_dtd` is True, and input file does not conform to the DTD
        &#34;&#34;&#34;
        tree = etree.parse(naf_file, etree.XMLParser(remove_blank_text=True, strip_cdata=False))

        if validate_against_dtd:
            validate_dtd(tree)

        return NafParser(tree, decorate=decorate)

    def write(self, file_path):
        &#34;&#34;&#34;Write NAF tree to file or stdout if no file path is given&#34;&#34;&#34;
        if file_path is None:
            print(etree.tostring(self.root, encoding=&#39;UTF-8&#39;, pretty_print=True, xml_declaration=True))
        else:
            self.tree.write(file_path, encoding=&#39;UTF-8&#39;, pretty_print=True, xml_declaration=True)

    def has_layer(self, layer: str):
        &#34;&#34;&#34;Returns True if layer with given name exists&#34;&#34;&#34;
        return self.root.findall(&#39;.//{}&#39;.format(layer))

    def get(self, layer_name: str):
        &#34;&#34;&#34;Return a layer object for the layer with the given layer-name.

        Returns only the first object if more elements carry the same name.&#34;&#34;&#34;
        if not self.has_layer(layer_name):
            raise ValueError(&#34;layer {} does not exist&#34;.format(layer_name))
        nodes = self.root.findall(&#39;.//{}&#39;.format(layer_name))
        return create_from_node[layer_name](nodes[0])

    def getall(self, layer_name: str):
        &#34;&#34;&#34;Return a list of layer objects for each layer carrying the given layer-name
        &#34;&#34;&#34;
        if not self.has_layer(layer_name):
            raise ValueError(&#34;layer {} does not exist&#34;.format(layer_name))
        nodes = self.root.findall(&#39;.//{}&#39;.format(layer_name))
        return [create_from_node[layer_name](node) for node in nodes]

    def add_layer(self, layer_name: str, element: Any, exist_ok=False):
        &#34;&#34;&#34;Add a layer to the NAF xml tree

        Parameters
        ----------
        layer_name : str
            naf layer name
        element : Any
            layer object
        exist_ok : bool
            allows replacement of existing layer

        Raises
        ------
        ValueError: if layer already exists and `exist_ok` is False
        &#34;&#34;&#34;
        if self.has_layer(layer_name) and not exist_ok:
            raise ValueError(&#39;Layer {} already exists&#39;.format(layer_name))
        else:
            if self.has_layer(layer_name):
                self.root.remove(self.root.find(layer_name))
            self.root.append(element.node())
            if layer_name in (&#39;text&#39;, &#39;terms&#39;):
                self.reset_targets2indices()
            if self.decorate:
                self.add_comments()

    def add_layer_from_elements(self, layer_name: str, elements: list, exist_ok=False):
        &#34;&#34;&#34;Create container layer from its elements.

        This method can be applied to non-empty layers without attributes. This concerns almost all layers,
        except for `NafHeader`, `Raw` and `TemporalRelations`

        Parameters
        ----------
        layer_name : str
            naf layer name
        elements : list
            list of layer elements objects
        exist_ok : bool
            allows replacement of existing layer

        Raises
        ------
        ValueError: if layer already exists and `exist_ok` is False
        &#34;&#34;&#34;
        self.add_layer(layer_name,
                       create_from_elements[layer_name](elements),
                       exist_ok=exist_ok)

    def add_naf_header(self, fileDesc_attrs={}, public_attrs={}, linguistic_processors=[], exist_ok=False):
        &#34;&#34;&#34;
        Create and add `nafHeader` layer

        Parameters
        ----------
        fileDesc_attrs : dict
            `fileDesc` layer attributes
        public_attrs : dict
            `public` layer attributes
        linguistic_processors : list[LinguisticProcessors]
            list of `LinguisticProcessors` objects per layer
        exist_ok : bool
            allows replacement of existing layer
        &#34;&#34;&#34;
        self.add_layer(&#39;nafHeader&#39;, NafHeader.create(fileDesc_attrs, public_attrs, linguistic_processors), exist_ok)

    def add_linguistic_processor(self, layer: str, name: str, version: str, lpDependencies=[], attributes={},
                                 add_time_stamp=True, replace=False):
        &#34;&#34;&#34;Add a `linguistic processor` element to the linguistic processors list for the given layer.

        Creates a `nafHeader` layer and/or a `linguisticProcessors` layer if there is not one yet.

        Parameters
        ----------
        layer : str
            the name of the layer
        name : str
            the name of the linguistic processor
        version : str
            the version of the linguistic processor
        lpDependencies : List(LPDependency)
            list of linguistic processor dependencies
        attributes : dict
            optional linguistic processor attributes (&#39;timestamp&#39;, &#39;beginTimestamp&#39;, &#39;endTimestamp&#39;, &#39;hostname&#39;)
        add_time_stamp : bool
            create time stamp
        replace : bool
            replace or append to `lp` elements for that layer
        &#34;&#34;&#34;
        if not self.has_layer(&#39;nafHeader&#39;):
            self.add_naf_header()
        if add_time_stamp:
            attributes[&#39;timestamp&#39;] = datetime.datetime.now(datetime.timezone.utc).isoformat(timespec=&#39;seconds&#39;)
        self.add_lp(layer, LP(name, version, lpDependencies, attributes), replace)

    def add_lp(self, layer: str, linguistic_processor: LP, replace: bool):
        &#34;&#34;&#34;Add a linguistic processor element to the linguistic processors list for the given layer.

        Creates a `linguisticProcessors` layer if there is not one yet. Pre-existing linguistic processor elements are
        replaced if `replace` is True.

        Parameters
        ----------
        layer : str
            the name of the layer
        linguistic_processor : LP
            the linguistic processor
        replace : bool
            replace or append to `lp` elements for that layer
        &#34;&#34;&#34;
        naf_header_node = self.root.find(&#39;nafHeader&#39;)
        ling_processors_layer_nodes = [lps for lps in naf_header_node.findall(&#39;linguisticProcessors&#39;)
                                       if lps.get(&#39;layer&#39;) == layer]
        if not ling_processors_layer_nodes:
            ling_processors_layer_node = LinguisticProcessors(layer, [linguistic_processor]).node()
            naf_header_node.append(ling_processors_layer_node)
        elif replace:
            remove_lps(ling_processors_layer_nodes[0])
            ling_processors_layer_nodes[0].append(linguistic_processor.node())
        else:
            ling_processors_layer_nodes[0].append(linguistic_processor.node())

    def extend_lps(self, layer: str, linguistic_processors: List[LP], replace=False):
        &#34;&#34;&#34;Add linguistic processor elements to the linguistic processors list for the given layer.

        Creates a `linguisticProcessors` layer if there is not one yet.

        Parameters
        ----------
        layer : str
            the name of the layer
        linguistic_processors : List[LP]
            the linguistic processors
        &#34;&#34;&#34;
        naf_header_node = self.root.find(&#39;nafHeader&#39;)
        ling_processors_layer_nodes = [lps for lps in naf_header_node.findall(&#39;linguisticProcessors&#39;)
                                       if lps.get(&#39;layer&#39;) == layer]
        if not ling_processors_layer_nodes:
            ling_processors_layer_node = LinguisticProcessors(layer, linguistic_processors).node()
            naf_header_node.append(ling_processors_layer_node)
        elif replace:
            remove_lps(ling_processors_layer_nodes[0])
            ling_processors_layer_nodes[0] = [lp.node() for lp in linguistic_processors]
        else:
            ling_processors_layer_nodes[0].extend([lp.node() for lp in linguistic_processors])

    def add_raw_layer(self, text: str, exist_ok=False):
        &#34;&#34;&#34;Add (or replace) raw layer from text

        Parameters
        ----------
        text : str
            raw layer text
        exist_ok : bool
            allows replacement of existing layer&#34;&#34;&#34;
        self.add_layer(&#39;raw&#39;, Raw(text), exist_ok)

    def get_lps(self, layer_name):
        &#34;&#34;&#34;Return list of linguistic processors for a given layer

        Parameters
        ----------
        layer_name: str
            layer name

        Returns
        -------
        list of Lp objects

        Raises
        ------
        ValueError: if the NAF header has no linguisticProcessors element for that layer&#34;&#34;&#34;

        lprocessors = [x for x in self.getall(&#39;linguisticProcessors&#39;) if x.layer_name == layer_name]
        if lprocessors:
            return lprocessors[0].lps
        else:
            return None

    def targets2indices(self) -&gt; Dict[str, Tuple[int, int]]:
        &#34;&#34;&#34;Map each word form, subtoken or term id to its begin and end indices

        Returns
        -------
        map of target ids to start and end indices
        &#34;&#34;&#34;
        if not self.has_layer(&#39;text&#39;):
            return {}
        id_map = {}
        for wf in self.get(&#39;text&#39;):
            id_map[wf.id] = (int(wf.offset), int(wf.offset) + int(wf.length))
            if wf.subtokens:
                id_map.update({st.id: (int(st.offset), int(st.offset) + int(st.length)) for st in wf.subtokens})
        if self.has_layer(&#39;terms&#39;):     # higher layers may reference to terms
            # map term ids to begin/end indices through word-form ids
            twf_map = {t.id: id_map[t.span.target_ids()[0]] for t in self.get(&#39;terms&#39;)}
            id_map.update(twf_map)
        return id_map

    def add_comments(self):
        &#34;&#34;&#34;Add covered text as comment to all Span elements that have no comment yet&#34;&#34;&#34;
        spans = [x for x in self.root.findall(&#39;.//span&#39;) if not [_ for _ in x.iter(tag=etree.Comment)]]
        target_ids = [[t.get(&#39;id&#39;) for t in span.findall(&#39;target&#39;)] for span in spans]
        if spans and not self.id_map:
            self.id_map = self.targets2indices()
        for span_node, tid_span in zip(spans, target_ids):
            begin, end = self.id_map[tid_span[0]][0], self.id_map[tid_span[-1]][1]
            comment = self.get(&#39;raw&#39;).text[begin:end]
            comment = comment.replace(&#39;--&#39;, &#39;-~&#39;)
            comment = re.sub(&#39;-$&#39;, &#39;~&#39;, comment)
            span_node.append(etree.Comment(comment))

    def covered_text(self, target_ids: List[str]) -&gt; str:
        &#34;&#34;&#34;Return text covered by the target ids

        Parameters
        ----------
        target_ids: List[str]
            target ids

        Returns
        -------
        covered text
        &#34;&#34;&#34;
        start, end = self.start_end_indices(target_ids)
        return self.get(&#39;raw&#39;).text[start:end]

    def start_end_indices(self, target_ids: List[str]) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;Return the start and end indices of the span represented by the target ids

        Parameters
        ----------
        target_ids: List[str]
            target ids

        Returns
        -------
        tuple of start and end indices
        &#34;&#34;&#34;
        if not self.id_map:
            self.id_map = self.targets2indices()
            if not self.id_map:
                raise ValueError(&#39;No target ids found&#39;)
        return self.id_map[target_ids[0]][0], self.id_map[target_ids[-1]][1]

    def reset_targets2indices(self):
        &#34;&#34;&#34;Recomputes the mapping of all word forms, subtokens and terms to their start and end indices.

        This mapping is computed in a restricted number of cases: when loading a existing NAF document, or when
        retrieving the covered text on a newly created NAF document. The present function can be called when
        adding layers for which the mapping will be relevant, such as subtokens or terms on a NAF document already
        annotated with word forms.
        &#34;&#34;&#34;
        self.id_map = self.targets2indices()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="nafparserpy.parser.remove_lps"><code class="name flex">
<span>def <span class="ident">remove_lps</span></span>(<span>ling_processors_layer_node)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_lps(ling_processors_layer_node):
    lps = [child for child in ling_processors_layer_node]
    for lp in lps:
        ling_processors_layer_node.remove(lp)</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.split_naf_header_attrs"><code class="name flex">
<span>def <span class="ident">split_naf_header_attrs</span></span>(<span>attrs)</span>
</code></dt>
<dd>
<div class="desc"><p>Split input attributes in public or fileDesc attributes</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>attrs</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary of public/fileDesc attributes</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>a tuple</code> of <code>attribute dictionaries for fileDesc and public</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>KeyError</code></strong> :&ensp;<code>if the input dictionary contains keywords not pertaining to public/fileDesc attributes</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_naf_header_attrs(attrs):
    &#34;&#34;&#34;Split input attributes in public or fileDesc attributes

    Parameters
    ----------
    attrs : dict
        dictionary of public/fileDesc attributes

    Returns
    -------
    a tuple of attribute dictionaries for fileDesc and public

    Raises
    ------
    KeyError: if the input dictionary contains keywords not pertaining to public/fileDesc attributes
        &#34;&#34;&#34;
    public_attrs = {}
    filedesc_attrs = {}
    public_keys = [&#39;publicId&#39;, &#39;uri&#39;]
    filedesc_keys = [&#39;title&#39;, &#39;author&#39;, &#39;creationtime&#39;, &#39;filename&#39;, &#39;filetype&#39;, &#39;pages&#39;]
    for k in attrs:
        if k in public_keys:
            public_attrs.update({k: attrs[k]})
        elif k in filedesc_keys:
            filedesc_attrs.update({k: attrs[k]})
        else:
            raise KeyError(&#39;unknown public/fileDesc key: {}&#39;.format(k))
    return filedesc_attrs, public_attrs</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.validate_dtd"><code class="name flex">
<span>def <span class="ident">validate_dtd</span></span>(<span>tree, dtd='naf_v3.3.dtd')</span>
</code></dt>
<dd>
<div class="desc"><p>Validate tree against DTD</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tree</code></strong> :&ensp;<code>ElementTree</code></dt>
<dd>NAF tree</dd>
<dt><strong><code>dtd</code></strong> :&ensp;<code>str</code></dt>
<dd>path to DTD</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong> :&ensp;<code>if tree is not valid</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_dtd(tree, dtd=&#39;naf_v3.3.dtd&#39;):
    &#34;&#34;&#34;Validate tree against DTD

    Parameters
    ----------
    tree : ElementTree
        NAF tree
    dtd : str
        path to DTD

    Raises
    ------
    ValueError : if tree is not valid
    &#34;&#34;&#34;
    with open(dtd) as infile:
        dtd = etree.DTD(infile)
    if not dtd.validate(tree.getroot()):
        raise ValueError(f&#34;Input tree does not conform to DTD {dtd}&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="nafparserpy.parser.NafParser"><code class="flex name class">
<span>class <span class="ident">NafParser</span></span>
<span>(</span><span>tree=None, lang='en', version=None, decorate=True, **attrs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a NAF document from an existing tree or from scratch.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tree</code></strong> :&ensp;<code>etree</code></dt>
<dd>input tree</dd>
<dt><strong><code>lang</code></strong> :&ensp;<code>str</code></dt>
<dd>document language, defaults to <code>en</code>. This parameter is ignored if tree is not None</dd>
<dt><strong><code>version</code></strong> :&ensp;<code>str</code></dt>
<dd>NAF version, defaults to <code>parser.NAF_VERSION</code>; ignored if tree is not None</dd>
<dt><strong><code>decorate</code></strong> :&ensp;<code>bool</code></dt>
<dd>adds covered text to span nodes</dd>
<dt><strong><code>attrs</code></strong> :&ensp;<code>dict</code></dt>
<dd>nafHeader fileDesc and public attributes; ignored if tree is not None</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NafParser:
    def __init__(self, tree=None, lang=&#39;en&#39;, version=None, decorate=True, **attrs):
        &#34;&#34;&#34;
        Create a NAF document from an existing tree or from scratch.

        Parameters
        ----------
        tree : etree
            input tree
        lang : str
            document language, defaults to `en`. This parameter is ignored if tree is not None
        version : str
            NAF version, defaults to `parser.NAF_VERSION`; ignored if tree is not None
        decorate : bool
            adds covered text to span nodes
        attrs : dict
            nafHeader fileDesc and public attributes; ignored if tree is not None
        &#34;&#34;&#34;
        self.decorate = decorate
        naf_version = NAF_VERSION
        if version is not None:
            naf_version = version
        if tree is None:
            self.tree = etree.ElementTree(etree.Element(&#39;NAF&#39;))
            self.root = self.tree.getroot()
            self.root.set(&#39;{http://www.w3.org/XML/1998/namespace}lang&#39;, lang)
            self.root.set(&#39;version&#39;, naf_version)
            if attrs:
                filedesc_attrs, public_attrs = split_naf_header_attrs(attrs)
                self.add_naf_header(fileDesc_attrs=filedesc_attrs, public_attrs=public_attrs)
            self.id_map = {}
        else:
            self.tree = tree
            self.root = self.tree.getroot()
            self.id_map = self.targets2indices()

    @staticmethod
    def load(naf_file, validate_against_dtd=False, decorate=True):
        &#34;&#34;&#34;Create a NAF document from a NAF file

        Parameters
        ----------
        naf_file : str
            path to NAF file
        validate_against_dtd : bool
            validates input tree against DTD if True
        decorate : bool
            adds covered text to span nodes

        Raises
        ------
        ValueError: if `validate_against_dtd` is True, and input file does not conform to the DTD
        &#34;&#34;&#34;
        tree = etree.parse(naf_file, etree.XMLParser(remove_blank_text=True, strip_cdata=False))

        if validate_against_dtd:
            validate_dtd(tree)

        return NafParser(tree, decorate=decorate)

    def write(self, file_path):
        &#34;&#34;&#34;Write NAF tree to file or stdout if no file path is given&#34;&#34;&#34;
        if file_path is None:
            print(etree.tostring(self.root, encoding=&#39;UTF-8&#39;, pretty_print=True, xml_declaration=True))
        else:
            self.tree.write(file_path, encoding=&#39;UTF-8&#39;, pretty_print=True, xml_declaration=True)

    def has_layer(self, layer: str):
        &#34;&#34;&#34;Returns True if layer with given name exists&#34;&#34;&#34;
        return self.root.findall(&#39;.//{}&#39;.format(layer))

    def get(self, layer_name: str):
        &#34;&#34;&#34;Return a layer object for the layer with the given layer-name.

        Returns only the first object if more elements carry the same name.&#34;&#34;&#34;
        if not self.has_layer(layer_name):
            raise ValueError(&#34;layer {} does not exist&#34;.format(layer_name))
        nodes = self.root.findall(&#39;.//{}&#39;.format(layer_name))
        return create_from_node[layer_name](nodes[0])

    def getall(self, layer_name: str):
        &#34;&#34;&#34;Return a list of layer objects for each layer carrying the given layer-name
        &#34;&#34;&#34;
        if not self.has_layer(layer_name):
            raise ValueError(&#34;layer {} does not exist&#34;.format(layer_name))
        nodes = self.root.findall(&#39;.//{}&#39;.format(layer_name))
        return [create_from_node[layer_name](node) for node in nodes]

    def add_layer(self, layer_name: str, element: Any, exist_ok=False):
        &#34;&#34;&#34;Add a layer to the NAF xml tree

        Parameters
        ----------
        layer_name : str
            naf layer name
        element : Any
            layer object
        exist_ok : bool
            allows replacement of existing layer

        Raises
        ------
        ValueError: if layer already exists and `exist_ok` is False
        &#34;&#34;&#34;
        if self.has_layer(layer_name) and not exist_ok:
            raise ValueError(&#39;Layer {} already exists&#39;.format(layer_name))
        else:
            if self.has_layer(layer_name):
                self.root.remove(self.root.find(layer_name))
            self.root.append(element.node())
            if layer_name in (&#39;text&#39;, &#39;terms&#39;):
                self.reset_targets2indices()
            if self.decorate:
                self.add_comments()

    def add_layer_from_elements(self, layer_name: str, elements: list, exist_ok=False):
        &#34;&#34;&#34;Create container layer from its elements.

        This method can be applied to non-empty layers without attributes. This concerns almost all layers,
        except for `NafHeader`, `Raw` and `TemporalRelations`

        Parameters
        ----------
        layer_name : str
            naf layer name
        elements : list
            list of layer elements objects
        exist_ok : bool
            allows replacement of existing layer

        Raises
        ------
        ValueError: if layer already exists and `exist_ok` is False
        &#34;&#34;&#34;
        self.add_layer(layer_name,
                       create_from_elements[layer_name](elements),
                       exist_ok=exist_ok)

    def add_naf_header(self, fileDesc_attrs={}, public_attrs={}, linguistic_processors=[], exist_ok=False):
        &#34;&#34;&#34;
        Create and add `nafHeader` layer

        Parameters
        ----------
        fileDesc_attrs : dict
            `fileDesc` layer attributes
        public_attrs : dict
            `public` layer attributes
        linguistic_processors : list[LinguisticProcessors]
            list of `LinguisticProcessors` objects per layer
        exist_ok : bool
            allows replacement of existing layer
        &#34;&#34;&#34;
        self.add_layer(&#39;nafHeader&#39;, NafHeader.create(fileDesc_attrs, public_attrs, linguistic_processors), exist_ok)

    def add_linguistic_processor(self, layer: str, name: str, version: str, lpDependencies=[], attributes={},
                                 add_time_stamp=True, replace=False):
        &#34;&#34;&#34;Add a `linguistic processor` element to the linguistic processors list for the given layer.

        Creates a `nafHeader` layer and/or a `linguisticProcessors` layer if there is not one yet.

        Parameters
        ----------
        layer : str
            the name of the layer
        name : str
            the name of the linguistic processor
        version : str
            the version of the linguistic processor
        lpDependencies : List(LPDependency)
            list of linguistic processor dependencies
        attributes : dict
            optional linguistic processor attributes (&#39;timestamp&#39;, &#39;beginTimestamp&#39;, &#39;endTimestamp&#39;, &#39;hostname&#39;)
        add_time_stamp : bool
            create time stamp
        replace : bool
            replace or append to `lp` elements for that layer
        &#34;&#34;&#34;
        if not self.has_layer(&#39;nafHeader&#39;):
            self.add_naf_header()
        if add_time_stamp:
            attributes[&#39;timestamp&#39;] = datetime.datetime.now(datetime.timezone.utc).isoformat(timespec=&#39;seconds&#39;)
        self.add_lp(layer, LP(name, version, lpDependencies, attributes), replace)

    def add_lp(self, layer: str, linguistic_processor: LP, replace: bool):
        &#34;&#34;&#34;Add a linguistic processor element to the linguistic processors list for the given layer.

        Creates a `linguisticProcessors` layer if there is not one yet. Pre-existing linguistic processor elements are
        replaced if `replace` is True.

        Parameters
        ----------
        layer : str
            the name of the layer
        linguistic_processor : LP
            the linguistic processor
        replace : bool
            replace or append to `lp` elements for that layer
        &#34;&#34;&#34;
        naf_header_node = self.root.find(&#39;nafHeader&#39;)
        ling_processors_layer_nodes = [lps for lps in naf_header_node.findall(&#39;linguisticProcessors&#39;)
                                       if lps.get(&#39;layer&#39;) == layer]
        if not ling_processors_layer_nodes:
            ling_processors_layer_node = LinguisticProcessors(layer, [linguistic_processor]).node()
            naf_header_node.append(ling_processors_layer_node)
        elif replace:
            remove_lps(ling_processors_layer_nodes[0])
            ling_processors_layer_nodes[0].append(linguistic_processor.node())
        else:
            ling_processors_layer_nodes[0].append(linguistic_processor.node())

    def extend_lps(self, layer: str, linguistic_processors: List[LP], replace=False):
        &#34;&#34;&#34;Add linguistic processor elements to the linguistic processors list for the given layer.

        Creates a `linguisticProcessors` layer if there is not one yet.

        Parameters
        ----------
        layer : str
            the name of the layer
        linguistic_processors : List[LP]
            the linguistic processors
        &#34;&#34;&#34;
        naf_header_node = self.root.find(&#39;nafHeader&#39;)
        ling_processors_layer_nodes = [lps for lps in naf_header_node.findall(&#39;linguisticProcessors&#39;)
                                       if lps.get(&#39;layer&#39;) == layer]
        if not ling_processors_layer_nodes:
            ling_processors_layer_node = LinguisticProcessors(layer, linguistic_processors).node()
            naf_header_node.append(ling_processors_layer_node)
        elif replace:
            remove_lps(ling_processors_layer_nodes[0])
            ling_processors_layer_nodes[0] = [lp.node() for lp in linguistic_processors]
        else:
            ling_processors_layer_nodes[0].extend([lp.node() for lp in linguistic_processors])

    def add_raw_layer(self, text: str, exist_ok=False):
        &#34;&#34;&#34;Add (or replace) raw layer from text

        Parameters
        ----------
        text : str
            raw layer text
        exist_ok : bool
            allows replacement of existing layer&#34;&#34;&#34;
        self.add_layer(&#39;raw&#39;, Raw(text), exist_ok)

    def get_lps(self, layer_name):
        &#34;&#34;&#34;Return list of linguistic processors for a given layer

        Parameters
        ----------
        layer_name: str
            layer name

        Returns
        -------
        list of Lp objects

        Raises
        ------
        ValueError: if the NAF header has no linguisticProcessors element for that layer&#34;&#34;&#34;

        lprocessors = [x for x in self.getall(&#39;linguisticProcessors&#39;) if x.layer_name == layer_name]
        if lprocessors:
            return lprocessors[0].lps
        else:
            return None

    def targets2indices(self) -&gt; Dict[str, Tuple[int, int]]:
        &#34;&#34;&#34;Map each word form, subtoken or term id to its begin and end indices

        Returns
        -------
        map of target ids to start and end indices
        &#34;&#34;&#34;
        if not self.has_layer(&#39;text&#39;):
            return {}
        id_map = {}
        for wf in self.get(&#39;text&#39;):
            id_map[wf.id] = (int(wf.offset), int(wf.offset) + int(wf.length))
            if wf.subtokens:
                id_map.update({st.id: (int(st.offset), int(st.offset) + int(st.length)) for st in wf.subtokens})
        if self.has_layer(&#39;terms&#39;):     # higher layers may reference to terms
            # map term ids to begin/end indices through word-form ids
            twf_map = {t.id: id_map[t.span.target_ids()[0]] for t in self.get(&#39;terms&#39;)}
            id_map.update(twf_map)
        return id_map

    def add_comments(self):
        &#34;&#34;&#34;Add covered text as comment to all Span elements that have no comment yet&#34;&#34;&#34;
        spans = [x for x in self.root.findall(&#39;.//span&#39;) if not [_ for _ in x.iter(tag=etree.Comment)]]
        target_ids = [[t.get(&#39;id&#39;) for t in span.findall(&#39;target&#39;)] for span in spans]
        if spans and not self.id_map:
            self.id_map = self.targets2indices()
        for span_node, tid_span in zip(spans, target_ids):
            begin, end = self.id_map[tid_span[0]][0], self.id_map[tid_span[-1]][1]
            comment = self.get(&#39;raw&#39;).text[begin:end]
            comment = comment.replace(&#39;--&#39;, &#39;-~&#39;)
            comment = re.sub(&#39;-$&#39;, &#39;~&#39;, comment)
            span_node.append(etree.Comment(comment))

    def covered_text(self, target_ids: List[str]) -&gt; str:
        &#34;&#34;&#34;Return text covered by the target ids

        Parameters
        ----------
        target_ids: List[str]
            target ids

        Returns
        -------
        covered text
        &#34;&#34;&#34;
        start, end = self.start_end_indices(target_ids)
        return self.get(&#39;raw&#39;).text[start:end]

    def start_end_indices(self, target_ids: List[str]) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;Return the start and end indices of the span represented by the target ids

        Parameters
        ----------
        target_ids: List[str]
            target ids

        Returns
        -------
        tuple of start and end indices
        &#34;&#34;&#34;
        if not self.id_map:
            self.id_map = self.targets2indices()
            if not self.id_map:
                raise ValueError(&#39;No target ids found&#39;)
        return self.id_map[target_ids[0]][0], self.id_map[target_ids[-1]][1]

    def reset_targets2indices(self):
        &#34;&#34;&#34;Recomputes the mapping of all word forms, subtokens and terms to their start and end indices.

        This mapping is computed in a restricted number of cases: when loading a existing NAF document, or when
        retrieving the covered text on a newly created NAF document. The present function can be called when
        adding layers for which the mapping will be relevant, such as subtokens or terms on a NAF document already
        annotated with word forms.
        &#34;&#34;&#34;
        self.id_map = self.targets2indices()</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="nafparserpy.parser.NafParser.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>naf_file, validate_against_dtd=False, decorate=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a NAF document from a NAF file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>naf_file</code></strong> :&ensp;<code>str</code></dt>
<dd>path to NAF file</dd>
<dt><strong><code>validate_against_dtd</code></strong> :&ensp;<code>bool</code></dt>
<dd>validates input tree against DTD if True</dd>
<dt><strong><code>decorate</code></strong> :&ensp;<code>bool</code></dt>
<dd>adds covered text to span nodes</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong> :&ensp;<code>if </code>validate_against_dtd<code> is True, and input file does not conform to the DTD</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def load(naf_file, validate_against_dtd=False, decorate=True):
    &#34;&#34;&#34;Create a NAF document from a NAF file

    Parameters
    ----------
    naf_file : str
        path to NAF file
    validate_against_dtd : bool
        validates input tree against DTD if True
    decorate : bool
        adds covered text to span nodes

    Raises
    ------
    ValueError: if `validate_against_dtd` is True, and input file does not conform to the DTD
    &#34;&#34;&#34;
    tree = etree.parse(naf_file, etree.XMLParser(remove_blank_text=True, strip_cdata=False))

    if validate_against_dtd:
        validate_dtd(tree)

    return NafParser(tree, decorate=decorate)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="nafparserpy.parser.NafParser.add_comments"><code class="name flex">
<span>def <span class="ident">add_comments</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Add covered text as comment to all Span elements that have no comment yet</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_comments(self):
    &#34;&#34;&#34;Add covered text as comment to all Span elements that have no comment yet&#34;&#34;&#34;
    spans = [x for x in self.root.findall(&#39;.//span&#39;) if not [_ for _ in x.iter(tag=etree.Comment)]]
    target_ids = [[t.get(&#39;id&#39;) for t in span.findall(&#39;target&#39;)] for span in spans]
    if spans and not self.id_map:
        self.id_map = self.targets2indices()
    for span_node, tid_span in zip(spans, target_ids):
        begin, end = self.id_map[tid_span[0]][0], self.id_map[tid_span[-1]][1]
        comment = self.get(&#39;raw&#39;).text[begin:end]
        comment = comment.replace(&#39;--&#39;, &#39;-~&#39;)
        comment = re.sub(&#39;-$&#39;, &#39;~&#39;, comment)
        span_node.append(etree.Comment(comment))</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.add_layer"><code class="name flex">
<span>def <span class="ident">add_layer</span></span>(<span>self, layer_name: str, element: Any, exist_ok=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a layer to the NAF xml tree</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layer_name</code></strong> :&ensp;<code>str</code></dt>
<dd>naf layer name</dd>
<dt><strong><code>element</code></strong> :&ensp;<code>Any</code></dt>
<dd>layer object</dd>
<dt><strong><code>exist_ok</code></strong> :&ensp;<code>bool</code></dt>
<dd>allows replacement of existing layer</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong> :&ensp;<code>if layer already exists and </code>exist_ok<code> is False</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_layer(self, layer_name: str, element: Any, exist_ok=False):
    &#34;&#34;&#34;Add a layer to the NAF xml tree

    Parameters
    ----------
    layer_name : str
        naf layer name
    element : Any
        layer object
    exist_ok : bool
        allows replacement of existing layer

    Raises
    ------
    ValueError: if layer already exists and `exist_ok` is False
    &#34;&#34;&#34;
    if self.has_layer(layer_name) and not exist_ok:
        raise ValueError(&#39;Layer {} already exists&#39;.format(layer_name))
    else:
        if self.has_layer(layer_name):
            self.root.remove(self.root.find(layer_name))
        self.root.append(element.node())
        if layer_name in (&#39;text&#39;, &#39;terms&#39;):
            self.reset_targets2indices()
        if self.decorate:
            self.add_comments()</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.add_layer_from_elements"><code class="name flex">
<span>def <span class="ident">add_layer_from_elements</span></span>(<span>self, layer_name: str, elements: list, exist_ok=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Create container layer from its elements.</p>
<p>This method can be applied to non-empty layers without attributes. This concerns almost all layers,
except for <code>NafHeader</code>, <code>Raw</code> and <code>TemporalRelations</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layer_name</code></strong> :&ensp;<code>str</code></dt>
<dd>naf layer name</dd>
<dt><strong><code>elements</code></strong> :&ensp;<code>list</code></dt>
<dd>list of layer elements objects</dd>
<dt><strong><code>exist_ok</code></strong> :&ensp;<code>bool</code></dt>
<dd>allows replacement of existing layer</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong> :&ensp;<code>if layer already exists and </code>exist_ok<code> is False</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_layer_from_elements(self, layer_name: str, elements: list, exist_ok=False):
    &#34;&#34;&#34;Create container layer from its elements.

    This method can be applied to non-empty layers without attributes. This concerns almost all layers,
    except for `NafHeader`, `Raw` and `TemporalRelations`

    Parameters
    ----------
    layer_name : str
        naf layer name
    elements : list
        list of layer elements objects
    exist_ok : bool
        allows replacement of existing layer

    Raises
    ------
    ValueError: if layer already exists and `exist_ok` is False
    &#34;&#34;&#34;
    self.add_layer(layer_name,
                   create_from_elements[layer_name](elements),
                   exist_ok=exist_ok)</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.add_linguistic_processor"><code class="name flex">
<span>def <span class="ident">add_linguistic_processor</span></span>(<span>self, layer: str, name: str, version: str, lpDependencies=[], attributes={}, add_time_stamp=True, replace=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a <code>linguistic processor</code> element to the linguistic processors list for the given layer.</p>
<p>Creates a <code>nafHeader</code> layer and/or a <code>linguisticProcessors</code> layer if there is not one yet.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layer</code></strong> :&ensp;<code>str</code></dt>
<dd>the name of the layer</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>the name of the linguistic processor</dd>
<dt><strong><code>version</code></strong> :&ensp;<code>str</code></dt>
<dd>the version of the linguistic processor</dd>
<dt><strong><code>lpDependencies</code></strong> :&ensp;<code>List(LPDependency)</code></dt>
<dd>list of linguistic processor dependencies</dd>
<dt><strong><code>attributes</code></strong> :&ensp;<code>dict</code></dt>
<dd>optional linguistic processor attributes ('timestamp', 'beginTimestamp', 'endTimestamp', 'hostname')</dd>
<dt><strong><code>add_time_stamp</code></strong> :&ensp;<code>bool</code></dt>
<dd>create time stamp</dd>
<dt><strong><code>replace</code></strong> :&ensp;<code>bool</code></dt>
<dd>replace or append to <code>lp</code> elements for that layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_linguistic_processor(self, layer: str, name: str, version: str, lpDependencies=[], attributes={},
                             add_time_stamp=True, replace=False):
    &#34;&#34;&#34;Add a `linguistic processor` element to the linguistic processors list for the given layer.

    Creates a `nafHeader` layer and/or a `linguisticProcessors` layer if there is not one yet.

    Parameters
    ----------
    layer : str
        the name of the layer
    name : str
        the name of the linguistic processor
    version : str
        the version of the linguistic processor
    lpDependencies : List(LPDependency)
        list of linguistic processor dependencies
    attributes : dict
        optional linguistic processor attributes (&#39;timestamp&#39;, &#39;beginTimestamp&#39;, &#39;endTimestamp&#39;, &#39;hostname&#39;)
    add_time_stamp : bool
        create time stamp
    replace : bool
        replace or append to `lp` elements for that layer
    &#34;&#34;&#34;
    if not self.has_layer(&#39;nafHeader&#39;):
        self.add_naf_header()
    if add_time_stamp:
        attributes[&#39;timestamp&#39;] = datetime.datetime.now(datetime.timezone.utc).isoformat(timespec=&#39;seconds&#39;)
    self.add_lp(layer, LP(name, version, lpDependencies, attributes), replace)</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.add_lp"><code class="name flex">
<span>def <span class="ident">add_lp</span></span>(<span>self, layer: str, linguistic_processor: <a title="nafparserpy.layers.naf_header.LP" href="layers/naf_header.html#nafparserpy.layers.naf_header.LP">LP</a>, replace: bool)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a linguistic processor element to the linguistic processors list for the given layer.</p>
<p>Creates a <code>linguisticProcessors</code> layer if there is not one yet. Pre-existing linguistic processor elements are
replaced if <code>replace</code> is True.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layer</code></strong> :&ensp;<code>str</code></dt>
<dd>the name of the layer</dd>
<dt><strong><code>linguistic_processor</code></strong> :&ensp;<code>LP</code></dt>
<dd>the linguistic processor</dd>
<dt><strong><code>replace</code></strong> :&ensp;<code>bool</code></dt>
<dd>replace or append to <code>lp</code> elements for that layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_lp(self, layer: str, linguistic_processor: LP, replace: bool):
    &#34;&#34;&#34;Add a linguistic processor element to the linguistic processors list for the given layer.

    Creates a `linguisticProcessors` layer if there is not one yet. Pre-existing linguistic processor elements are
    replaced if `replace` is True.

    Parameters
    ----------
    layer : str
        the name of the layer
    linguistic_processor : LP
        the linguistic processor
    replace : bool
        replace or append to `lp` elements for that layer
    &#34;&#34;&#34;
    naf_header_node = self.root.find(&#39;nafHeader&#39;)
    ling_processors_layer_nodes = [lps for lps in naf_header_node.findall(&#39;linguisticProcessors&#39;)
                                   if lps.get(&#39;layer&#39;) == layer]
    if not ling_processors_layer_nodes:
        ling_processors_layer_node = LinguisticProcessors(layer, [linguistic_processor]).node()
        naf_header_node.append(ling_processors_layer_node)
    elif replace:
        remove_lps(ling_processors_layer_nodes[0])
        ling_processors_layer_nodes[0].append(linguistic_processor.node())
    else:
        ling_processors_layer_nodes[0].append(linguistic_processor.node())</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.add_naf_header"><code class="name flex">
<span>def <span class="ident">add_naf_header</span></span>(<span>self, fileDesc_attrs={}, public_attrs={}, linguistic_processors=[], exist_ok=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Create and add <code>nafHeader</code> layer</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fileDesc_attrs</code></strong> :&ensp;<code>dict</code></dt>
<dd><code>fileDesc</code> layer attributes</dd>
<dt><strong><code>public_attrs</code></strong> :&ensp;<code>dict</code></dt>
<dd><code>public</code> layer attributes</dd>
<dt><strong><code>linguistic_processors</code></strong> :&ensp;<code>list[LinguisticProcessors]</code></dt>
<dd>list of <code>LinguisticProcessors</code> objects per layer</dd>
<dt><strong><code>exist_ok</code></strong> :&ensp;<code>bool</code></dt>
<dd>allows replacement of existing layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_naf_header(self, fileDesc_attrs={}, public_attrs={}, linguistic_processors=[], exist_ok=False):
    &#34;&#34;&#34;
    Create and add `nafHeader` layer

    Parameters
    ----------
    fileDesc_attrs : dict
        `fileDesc` layer attributes
    public_attrs : dict
        `public` layer attributes
    linguistic_processors : list[LinguisticProcessors]
        list of `LinguisticProcessors` objects per layer
    exist_ok : bool
        allows replacement of existing layer
    &#34;&#34;&#34;
    self.add_layer(&#39;nafHeader&#39;, NafHeader.create(fileDesc_attrs, public_attrs, linguistic_processors), exist_ok)</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.add_raw_layer"><code class="name flex">
<span>def <span class="ident">add_raw_layer</span></span>(<span>self, text: str, exist_ok=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add (or replace) raw layer from text</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>text</code></strong> :&ensp;<code>str</code></dt>
<dd>raw layer text</dd>
<dt><strong><code>exist_ok</code></strong> :&ensp;<code>bool</code></dt>
<dd>allows replacement of existing layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_raw_layer(self, text: str, exist_ok=False):
    &#34;&#34;&#34;Add (or replace) raw layer from text

    Parameters
    ----------
    text : str
        raw layer text
    exist_ok : bool
        allows replacement of existing layer&#34;&#34;&#34;
    self.add_layer(&#39;raw&#39;, Raw(text), exist_ok)</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.covered_text"><code class="name flex">
<span>def <span class="ident">covered_text</span></span>(<span>self, target_ids: List[str]) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Return text covered by the target ids</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>target_ids</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>target ids</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>covered text</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def covered_text(self, target_ids: List[str]) -&gt; str:
    &#34;&#34;&#34;Return text covered by the target ids

    Parameters
    ----------
    target_ids: List[str]
        target ids

    Returns
    -------
    covered text
    &#34;&#34;&#34;
    start, end = self.start_end_indices(target_ids)
    return self.get(&#39;raw&#39;).text[start:end]</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.extend_lps"><code class="name flex">
<span>def <span class="ident">extend_lps</span></span>(<span>self, layer: str, linguistic_processors: List[<a title="nafparserpy.layers.naf_header.LP" href="layers/naf_header.html#nafparserpy.layers.naf_header.LP">LP</a>], replace=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add linguistic processor elements to the linguistic processors list for the given layer.</p>
<p>Creates a <code>linguisticProcessors</code> layer if there is not one yet.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layer</code></strong> :&ensp;<code>str</code></dt>
<dd>the name of the layer</dd>
<dt><strong><code>linguistic_processors</code></strong> :&ensp;<code>List[LP]</code></dt>
<dd>the linguistic processors</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extend_lps(self, layer: str, linguistic_processors: List[LP], replace=False):
    &#34;&#34;&#34;Add linguistic processor elements to the linguistic processors list for the given layer.

    Creates a `linguisticProcessors` layer if there is not one yet.

    Parameters
    ----------
    layer : str
        the name of the layer
    linguistic_processors : List[LP]
        the linguistic processors
    &#34;&#34;&#34;
    naf_header_node = self.root.find(&#39;nafHeader&#39;)
    ling_processors_layer_nodes = [lps for lps in naf_header_node.findall(&#39;linguisticProcessors&#39;)
                                   if lps.get(&#39;layer&#39;) == layer]
    if not ling_processors_layer_nodes:
        ling_processors_layer_node = LinguisticProcessors(layer, linguistic_processors).node()
        naf_header_node.append(ling_processors_layer_node)
    elif replace:
        remove_lps(ling_processors_layer_nodes[0])
        ling_processors_layer_nodes[0] = [lp.node() for lp in linguistic_processors]
    else:
        ling_processors_layer_nodes[0].extend([lp.node() for lp in linguistic_processors])</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self, layer_name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a layer object for the layer with the given layer-name.</p>
<p>Returns only the first object if more elements carry the same name.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, layer_name: str):
    &#34;&#34;&#34;Return a layer object for the layer with the given layer-name.

    Returns only the first object if more elements carry the same name.&#34;&#34;&#34;
    if not self.has_layer(layer_name):
        raise ValueError(&#34;layer {} does not exist&#34;.format(layer_name))
    nodes = self.root.findall(&#39;.//{}&#39;.format(layer_name))
    return create_from_node[layer_name](nodes[0])</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.get_lps"><code class="name flex">
<span>def <span class="ident">get_lps</span></span>(<span>self, layer_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of linguistic processors for a given layer</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>layer_name</code></strong> :&ensp;<code>str</code></dt>
<dd>layer name</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>Lp objects</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong> :&ensp;<code>if the NAF header has no linguisticProcessors element for that layer</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_lps(self, layer_name):
    &#34;&#34;&#34;Return list of linguistic processors for a given layer

    Parameters
    ----------
    layer_name: str
        layer name

    Returns
    -------
    list of Lp objects

    Raises
    ------
    ValueError: if the NAF header has no linguisticProcessors element for that layer&#34;&#34;&#34;

    lprocessors = [x for x in self.getall(&#39;linguisticProcessors&#39;) if x.layer_name == layer_name]
    if lprocessors:
        return lprocessors[0].lps
    else:
        return None</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.getall"><code class="name flex">
<span>def <span class="ident">getall</span></span>(<span>self, layer_name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a list of layer objects for each layer carrying the given layer-name</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getall(self, layer_name: str):
    &#34;&#34;&#34;Return a list of layer objects for each layer carrying the given layer-name
    &#34;&#34;&#34;
    if not self.has_layer(layer_name):
        raise ValueError(&#34;layer {} does not exist&#34;.format(layer_name))
    nodes = self.root.findall(&#39;.//{}&#39;.format(layer_name))
    return [create_from_node[layer_name](node) for node in nodes]</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.has_layer"><code class="name flex">
<span>def <span class="ident">has_layer</span></span>(<span>self, layer: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if layer with given name exists</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def has_layer(self, layer: str):
    &#34;&#34;&#34;Returns True if layer with given name exists&#34;&#34;&#34;
    return self.root.findall(&#39;.//{}&#39;.format(layer))</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.reset_targets2indices"><code class="name flex">
<span>def <span class="ident">reset_targets2indices</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Recomputes the mapping of all word forms, subtokens and terms to their start and end indices.</p>
<p>This mapping is computed in a restricted number of cases: when loading a existing NAF document, or when
retrieving the covered text on a newly created NAF document. The present function can be called when
adding layers for which the mapping will be relevant, such as subtokens or terms on a NAF document already
annotated with word forms.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_targets2indices(self):
    &#34;&#34;&#34;Recomputes the mapping of all word forms, subtokens and terms to their start and end indices.

    This mapping is computed in a restricted number of cases: when loading a existing NAF document, or when
    retrieving the covered text on a newly created NAF document. The present function can be called when
    adding layers for which the mapping will be relevant, such as subtokens or terms on a NAF document already
    annotated with word forms.
    &#34;&#34;&#34;
    self.id_map = self.targets2indices()</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.start_end_indices"><code class="name flex">
<span>def <span class="ident">start_end_indices</span></span>(<span>self, target_ids: List[str]) ‑> Tuple[int, int]</span>
</code></dt>
<dd>
<div class="desc"><p>Return the start and end indices of the span represented by the target ids</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>target_ids</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>target ids</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code> of <code>start and end indices</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_end_indices(self, target_ids: List[str]) -&gt; Tuple[int, int]:
    &#34;&#34;&#34;Return the start and end indices of the span represented by the target ids

    Parameters
    ----------
    target_ids: List[str]
        target ids

    Returns
    -------
    tuple of start and end indices
    &#34;&#34;&#34;
    if not self.id_map:
        self.id_map = self.targets2indices()
        if not self.id_map:
            raise ValueError(&#39;No target ids found&#39;)
    return self.id_map[target_ids[0]][0], self.id_map[target_ids[-1]][1]</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.targets2indices"><code class="name flex">
<span>def <span class="ident">targets2indices</span></span>(<span>self) ‑> Dict[str, Tuple[int, int]]</span>
</code></dt>
<dd>
<div class="desc"><p>Map each word form, subtoken or term id to its begin and end indices</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>map</code> of <code>target ids to start and end indices</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def targets2indices(self) -&gt; Dict[str, Tuple[int, int]]:
    &#34;&#34;&#34;Map each word form, subtoken or term id to its begin and end indices

    Returns
    -------
    map of target ids to start and end indices
    &#34;&#34;&#34;
    if not self.has_layer(&#39;text&#39;):
        return {}
    id_map = {}
    for wf in self.get(&#39;text&#39;):
        id_map[wf.id] = (int(wf.offset), int(wf.offset) + int(wf.length))
        if wf.subtokens:
            id_map.update({st.id: (int(st.offset), int(st.offset) + int(st.length)) for st in wf.subtokens})
    if self.has_layer(&#39;terms&#39;):     # higher layers may reference to terms
        # map term ids to begin/end indices through word-form ids
        twf_map = {t.id: id_map[t.span.target_ids()[0]] for t in self.get(&#39;terms&#39;)}
        id_map.update(twf_map)
    return id_map</code></pre>
</details>
</dd>
<dt id="nafparserpy.parser.NafParser.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self, file_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Write NAF tree to file or stdout if no file path is given</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self, file_path):
    &#34;&#34;&#34;Write NAF tree to file or stdout if no file path is given&#34;&#34;&#34;
    if file_path is None:
        print(etree.tostring(self.root, encoding=&#39;UTF-8&#39;, pretty_print=True, xml_declaration=True))
    else:
        self.tree.write(file_path, encoding=&#39;UTF-8&#39;, pretty_print=True, xml_declaration=True)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="nafparserpy" href="index.html">nafparserpy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="nafparserpy.parser.remove_lps" href="#nafparserpy.parser.remove_lps">remove_lps</a></code></li>
<li><code><a title="nafparserpy.parser.split_naf_header_attrs" href="#nafparserpy.parser.split_naf_header_attrs">split_naf_header_attrs</a></code></li>
<li><code><a title="nafparserpy.parser.validate_dtd" href="#nafparserpy.parser.validate_dtd">validate_dtd</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="nafparserpy.parser.NafParser" href="#nafparserpy.parser.NafParser">NafParser</a></code></h4>
<ul class="">
<li><code><a title="nafparserpy.parser.NafParser.add_comments" href="#nafparserpy.parser.NafParser.add_comments">add_comments</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.add_layer" href="#nafparserpy.parser.NafParser.add_layer">add_layer</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.add_layer_from_elements" href="#nafparserpy.parser.NafParser.add_layer_from_elements">add_layer_from_elements</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.add_linguistic_processor" href="#nafparserpy.parser.NafParser.add_linguistic_processor">add_linguistic_processor</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.add_lp" href="#nafparserpy.parser.NafParser.add_lp">add_lp</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.add_naf_header" href="#nafparserpy.parser.NafParser.add_naf_header">add_naf_header</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.add_raw_layer" href="#nafparserpy.parser.NafParser.add_raw_layer">add_raw_layer</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.covered_text" href="#nafparserpy.parser.NafParser.covered_text">covered_text</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.extend_lps" href="#nafparserpy.parser.NafParser.extend_lps">extend_lps</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.get" href="#nafparserpy.parser.NafParser.get">get</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.get_lps" href="#nafparserpy.parser.NafParser.get_lps">get_lps</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.getall" href="#nafparserpy.parser.NafParser.getall">getall</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.has_layer" href="#nafparserpy.parser.NafParser.has_layer">has_layer</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.load" href="#nafparserpy.parser.NafParser.load">load</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.reset_targets2indices" href="#nafparserpy.parser.NafParser.reset_targets2indices">reset_targets2indices</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.start_end_indices" href="#nafparserpy.parser.NafParser.start_end_indices">start_end_indices</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.targets2indices" href="#nafparserpy.parser.NafParser.targets2indices">targets2indices</a></code></li>
<li><code><a title="nafparserpy.parser.NafParser.write" href="#nafparserpy.parser.NafParser.write">write</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>